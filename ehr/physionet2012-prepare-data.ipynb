{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physionet 2012 Mortality Prediction Challenge\n",
    "\n",
    "The [Physionet 2012](https://www.physionet.org/content/challenge-2012/1.0.0/) Computing in Cardiology Challenge is to develop methods for patient-specific prediction of in-hospital mortality.\n",
    "\n",
    "This notebook downloads and prepares the dataset as a tall and a wide table of timeseries observations and as a wide table of static observations. We will use [PySpark](https://spark.apache.org/docs/latest/api/python/index.html) to process the raw data and output parquet formatted datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "Each patient record is tall table in a `.txt` file with columns `Time`, `Parameter`, `Value`. For example:\n",
    "\n",
    "```\n",
    "Time,Parameter,Value\n",
    "00:00,RecordID,132539\n",
    "00:00,Age,54\n",
    "00:00,Gender,0\n",
    "00:00,Height,-1\n",
    "00:00,ICUType,4\n",
    "00:00,Weight,-1\n",
    "00:07,GCS,15\n",
    "00:07,HR,73\n",
    "00:07,NIDiasABP,65\n",
    "00:07,NIMAP,92.33\n",
    "00:07,NISysABP,147\n",
    "00:07,RespRate,19\n",
    "```\n",
    "\n",
    "We download the data from the Physionet website, concatenate each record into a dataframe and save the table as a `.parquet` file. We will add a column called `Dataset` to indicate the original dataset name. While we process the records, the `Time` column will also be transformed from a timestamp into an integer as minutes from ICU admission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import urllib\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "ROOT = Path(\"./data\")\n",
    "TIMESERIES_FILE = ROOT / \"physionet2012_timeseries.parquet\"\n",
    "STATIC_FILE = ROOT / \"physionet2012_static.parquet\"\n",
    "TIMESERIES_WIDE = ROOT / \"physionet2012_timeseries_wide.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url, root, filename=None):\n",
    "    if not filename:\n",
    "        filename = os.path.basename(url)\n",
    "    fpath = os.path.join(root, filename)\n",
    "    os.makedirs(root, exist_ok=True)\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, fpath)\n",
    "    except (urllib.error.URLError, IOError) as e:\n",
    "        if url[:5] == 'https':\n",
    "            url = url.replace('https:', 'http:')\n",
    "            urllib.request.urlretrieve(url, fpath)\n",
    "\n",
    "\n",
    "def unzip(file, root):\n",
    "    if file.endswith(\"tar.gz\"):\n",
    "        tar = tarfile.open(file, \"r:gz\")\n",
    "        tar.extractall(path=root)\n",
    "        tar.close()\n",
    "    if file.endswith(\"tar\"):\n",
    "        tar = tarfile.open(file, \"r:\")\n",
    "        tar.extractall(path=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set-a.tar.gz\n",
      "set-b.tar.gz\n",
      "set-c.tar.gz\n",
      "Outcomes-a.txt\n",
      "Outcomes-b.txt\n",
      "Outcomes-c.txt\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://physionet.org/files/challenge-2012/1.0.0/'\n",
    "files = [\n",
    "    'set-a.tar.gz',\n",
    "    'set-b.tar.gz',\n",
    "    'set-c.tar.gz',\n",
    "    'Outcomes-a.txt',\n",
    "    'Outcomes-b.txt',\n",
    "    'Outcomes-c.txt'\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    print(file)\n",
    "    download_url(base_url + file, ROOT)\n",
    "    unzip(os.path.join(ROOT, file), ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load each patient record and create a timeseries dataframe and a static variable dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['set-a','set-b','set-c']\n",
    "outcomes = ['Outcomes-a.txt','Outcomes-c.txt','Outcomes-c.txt']\n",
    "static_vars = [\n",
    "    'Age',\n",
    "    'Gender',\n",
    "    'Height',\n",
    "    'ICUType',\n",
    "    'Weight'\n",
    "]\n",
    "id_var = 'RecordID'\n",
    "time_var = 'Time'\n",
    "categorical = ['MechVent','Gender','ICUType']\n",
    "\n",
    "\n",
    "def load_dataset(root, name):\n",
    "    txt_all = list()\n",
    "    for f in os.listdir(root / name):\n",
    "        with open(root / name / f, 'r') as fp:\n",
    "            txt = fp.readlines()\n",
    "        # get recordid to add as a column\n",
    "        recordid = txt[1].rstrip('\\n').split(',')[-1]\n",
    "        txt = [t.rstrip('\\n').split(',') + [int(recordid)] for t in txt]\n",
    "        txt_all.extend(txt[1:])\n",
    "    df = pd.DataFrame(\n",
    "        txt_all,\n",
    "        columns=['Time', 'Parameter', 'Value', 'RecordID']\n",
    "    )\n",
    "    df.loc[:,'Dataset'] = name\n",
    "    return df\n",
    "\n",
    "\n",
    "def _parse_time_string_to_minutes(s):\n",
    "    hours, mins = s.split(':')\n",
    "    return (float(hours) + float(mins)/60) * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all datasets\n",
    "df = pd.concat([load_dataset(ROOT, name) for name in datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows without a parameter name\n",
    "df = df.loc[df.Parameter!=''].copy()\n",
    "# convert time to minutes from ICU admission\n",
    "df.loc[:,'Time'] = df.Time.apply(_parse_time_string_to_minutes)\n",
    "# drop static vars\n",
    "cols = static_vars + [id_var]\n",
    "timeseries = (df.loc[~df.Parameter.isin(cols)].copy())\n",
    "timeseries = (\n",
    "    timeseries\n",
    "    .sort_values(['Dataset','RecordID','Time'])\n",
    "    .reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static variables as a wide dataframe\n",
    "static = df.loc[\n",
    "    df.Parameter.isin(static_vars), \n",
    "    ['RecordID','Parameter','Value','Dataset']\n",
    "].copy()\n",
    "static = (\n",
    "    static\n",
    "    .groupby(['RecordID', 'Parameter', 'Dataset'])\n",
    "    [['Value']]\n",
    "    .last()\n",
    "    .reset_index()\n",
    "    .pivot(index=['Dataset','RecordID'], columns='Parameter',values='Value')\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge outcomes with static vars\n",
    "out = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(ROOT / f).assign(Dataset=datasets[i]) \n",
    "        for i, f in enumerate(outcomes)\n",
    "    ]\n",
    ")\n",
    "static = pd.merge(\n",
    "    static, \n",
    "    out, \n",
    "    how='inner', \n",
    "    left_on=['Dataset','RecordID'],\n",
    "    right_on=['Dataset','RecordID']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a timeseries and static dataframe, we can start cleaning the data by replacing missing values and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in static.columns:\n",
    "    if col == 'Dataset':\n",
    "        continue\n",
    "    static.loc[:, col] = pd.to_numeric(static.loc[:, col])\n",
    "timeseries.loc[:, 'Value'] = pd.to_numeric(timeseries.Value)\n",
    "\n",
    "static.replace(-1, np.nan, inplace=True)\n",
    "timeseries.replace(-1, np.nan, inplace=True)\n",
    "timeseries.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>ICUType</th>\n",
       "      <th>Weight</th>\n",
       "      <th>SAPS-I</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>Length_of_stay</th>\n",
       "      <th>Survival</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>set-a</td>\n",
       "      <td>132539</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>set-a</td>\n",
       "      <td>132540</td>\n",
       "      <td>76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.3</td>\n",
       "      <td>2</td>\n",
       "      <td>81.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>set-a</td>\n",
       "      <td>132541</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>56.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>set-a</td>\n",
       "      <td>132543</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.3</td>\n",
       "      <td>3</td>\n",
       "      <td>84.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>set-a</td>\n",
       "      <td>132545</td>\n",
       "      <td>88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  RecordID  Age  Gender  Height  ICUType  Weight  SAPS-I  SOFA  \\\n",
       "0   set-a    132539   54     0.0     NaN        4     NaN     6.0   1.0   \n",
       "1   set-a    132540   76     1.0   175.3        2    81.6    16.0   8.0   \n",
       "2   set-a    132541   44     0.0     NaN        3    56.7    21.0  11.0   \n",
       "3   set-a    132543   68     1.0   180.3        3    84.6     7.0   1.0   \n",
       "4   set-a    132545   88     0.0     NaN        3     NaN    17.0   2.0   \n",
       "\n",
       "   Length_of_stay  Survival  In-hospital_death  \n",
       "0             5.0       NaN                  0  \n",
       "1             8.0       NaN                  0  \n",
       "2            19.0       NaN                  0  \n",
       "3             9.0     575.0                  0  \n",
       "4             4.0     918.0                  0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Value</th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>GCS</td>\n",
       "      <td>15.00</td>\n",
       "      <td>132539</td>\n",
       "      <td>set-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>HR</td>\n",
       "      <td>73.00</td>\n",
       "      <td>132539</td>\n",
       "      <td>set-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NIDiasABP</td>\n",
       "      <td>65.00</td>\n",
       "      <td>132539</td>\n",
       "      <td>set-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NIMAP</td>\n",
       "      <td>92.33</td>\n",
       "      <td>132539</td>\n",
       "      <td>set-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>NISysABP</td>\n",
       "      <td>147.00</td>\n",
       "      <td>132539</td>\n",
       "      <td>set-a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time  Parameter   Value  RecordID Dataset\n",
       "0   7.0        GCS   15.00    132539   set-a\n",
       "1   7.0         HR   73.00    132539   set-a\n",
       "2   7.0  NIDiasABP   65.00    132539   set-a\n",
       "3   7.0      NIMAP   92.33    132539   set-a\n",
       "4   7.0   NISysABP  147.00    132539   set-a"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plausibility filters\n",
    "\n",
    "We use a CSV file to store the plausible ranges for every variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_csv = '''\n",
    "\"Variable\",\"NiceName\",\"PlausibilityLower\",\"PlausibilityUpper\",\"Outlier\"\n",
    "\"Albumin\",\"Serum Albumin (g/dL)\",1.2,4.8,\"cap\"\n",
    "\"ALP\",\"Alkaline phosphatase (IU/L)\",29,400,\"cap\"\n",
    "\"ALT\",\"Alanine transaminase (IU/L)\",6,458,\"cap\"\n",
    "\"AST\",\"Aspartate transaminase (IU/L)\",6,465,\"cap\"\n",
    "\"Bilirubin\",\"Bilirubin (mg/dL)\",0.1,24.8,\"cap\"\n",
    "\"BUN\",\"Blood urea nitrogen (mg/dL)\",3,118,\"cap\"\n",
    "\"Cholesterol\",\"Cholesterol (mg/dL)\",,,\"cap\"\n",
    "\"Creatinine\",\"Serum creatinine (mg/dL)\",0.28,10.23,\"cap\"\n",
    "\"DiasABP\",\"Invasive diastolic arterial blood pressure (mmHg)\",30,120,\"cap\"\n",
    "\"FiO2\",\"Fractional inspired O2 (0-1)\",0.21,1,\"cap\"\n",
    "\"GCS\",\"Glasgow Coma Score (3-15)\",,,\"cap\"\n",
    "\"Glucose\",\"Serum glucose (mg/dL)\",54,447,\"cap\"\n",
    "\"HCO3\",\"Serum bicarbonate (mmol/L)\",5,50,\"cap\"\n",
    "\"HCT\",\"Hematocrit (%)\",18,51,\"cap\"\n",
    "\"HR\",\"Heart rate (bpm)\",46,140,\"cap\"\n",
    "\"K\",\"Serum potassium (mEq/L)\",2.6,6.4,\"cap\"\n",
    "\"Lactate\",\"Lactate (mmol/L)\",0.4,14.2,\"cap\"\n",
    "\"Mg\",\"Serum magnesium (mmol/L)\",1.1,3.5,\"cap\"\n",
    "\"MAP\",\"Invasive mean arterial blood pressure (mmHg)\",40,203,\"cap\"\n",
    "\"MechVent\",\"Mechanical ventilation respiration\",0,1,\"cap\"\n",
    "\"Na\",\"Serum sodium (mEq/L)\",119,157,\"cap\"\n",
    "\"NIDiasABP\",\"Non-invasive diastolic arterial blood pressure (mmHg)\",30,120,\"cap\"\n",
    "\"NIMAP\",\"Non-invasive mean arterial blood pressure (mmHg)\",40,203,\"cap\"\n",
    "\"NISysABP\",\"Non-invasive systolic arterial blood pressure (mmHg)\",40,200,\"cap\"\n",
    "\"PaCO2\",\"partial pressure of arterial CO2 (mmHg)\",18,103,\"cap\"\n",
    "\"PaO2\",\"Partial pressure of arterial O2 (mmHg)\",0,550,\"cap\"\n",
    "\"pH\",\"Arterial pH (0-14)\",6,9,\"cap\"\n",
    "\"Platelets\",\"Platelets (cells/nL)\",,,\"cap\"\n",
    "\"RespRate\",\"Respiration rate (bpm)\",0,42,\"cap\"\n",
    "\"SaO2\",\"O2 saturation in hemoglobin (%)\",80,100,\"cap\"\n",
    "\"SysABP\",\"Invasive systolic arterial blood pressure (mmHg)\",40,200,\"cap\"\n",
    "\"Temp\",\"Temperature (C)\",32.94,40,\"cap\"\n",
    "\"TroponinI\",\"Troponin-I (ug/L)\",,,\"cap\"\n",
    "\"TroponinT\",\"Troponin-T (ug/L)\",,,\"cap\"\n",
    "\"Urine\",\"Urine output (mL)\",,,\"cap\"\n",
    "\"WBC\",\"White blood cell count (cells/nL)\",1.1,39.12,\"cap\"\n",
    "\"Weight\",\"Weight (kg)\",35,299,\"cap\"\n",
    "'''\n",
    "\n",
    "features = pd.read_csv(io.StringIO(features_csv)).set_index('Variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [apache-spark](https://spark.apache.org/) to process the datasets. PySpark lets us write modular code that can be reused across similar datasets and scales well as the dataset size gets larger. The PySpark API is also very functional and the builder design pattern to construct queries avoids messy string formatting and concatenation. Unlike Pandas, PySpark has query optimization to efficiently process the data.\n",
    "\n",
    "To install `apache-spark` on MacOS, run `brew install apache-spark`. The code below also needs the python packages `pyspark` and `findspark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spark(appName=\"MyApp\", memory=12):\n",
    "    \"\"\"\n",
    "    This function assumes you already have SPARK_HOME and PYSPARK_SUBMIT_ARGS \n",
    "    environment variables set. Requires findspark and PySpark.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import findspark\n",
    "\n",
    "    def _parse_master(pyspark_submit_args):\n",
    "        sargs = pyspark_submit_args.split()\n",
    "        for j, sarg in enumerate(sargs):\n",
    "            if sarg == \"--master\":\n",
    "                try:\n",
    "                    return sargs[j + 1]\n",
    "                except:\n",
    "                    raise Exception(\"Could not parse master from PYSPARK_SUBMIT_ARGS\")\n",
    "        raise Exception(\"Could not parse master from PYSPARK_SUBMIT_ARGS\")\n",
    "\n",
    "    if \"SPARK_HOME\" not in os.environ:\n",
    "        raise Exception(\"SPARK_HOME environment variable not set.\")\n",
    "    if \"PYSPARK_SUBMIT_ARGS\" not in os.environ:\n",
    "        os.environ[\n",
    "            \"PYSPARK_SUBMIT_ARGS\"\n",
    "        ] = f\"--master local[12] --driver-memory {memory}g --executor-memory {memory}g pyspark-shell\"\n",
    "    if \"PYSPARK_SUBMIT_ARGS\" not in os.environ:\n",
    "        # export PYSPARK_SUBMIT_ARGS = \" --master local[8] --driver-memory 8g --executor-memory 8g pyspark-shell\"\n",
    "        raise Exception(\"PYSPARK_SUNBMIT_ARGS environment variable not set.\")\n",
    "    findspark.init(os.environ[\"SPARK_HOME\"])\n",
    "    spark_master = _parse_master(os.environ[\"PYSPARK_SUBMIT_ARGS\"])\n",
    "\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "    spark = SparkSession.builder.master(spark_master).appName(appName).getOrCreate()\n",
    "    return spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://macc02y44r2jg5j:4040\n"
     ]
    }
   ],
   "source": [
    "os.environ.setdefault('SPARK_HOME', '/usr/local/Cellar/apache-spark/3.2.0/libexec')\n",
    "spark = init_spark(memory=4)\n",
    "print(spark.sparkContext.uiWebUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframes in spark\n",
    "timeseries = spark.createDataFrame(timeseries)\n",
    "static = spark.createDataFrame(static)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process the tall dataframe by applying plausibility filters on all columns with special handling for pH, Temperature, and FiO2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_var = 'Parameter'\n",
    "value_var = 'Value'\n",
    "parameter_col = F.col(parameter_var)\n",
    "value_col = F.col(value_var)\n",
    "\n",
    "# special pre-processing\n",
    "value = (\n",
    "    F.when((parameter_col == 'pH') & (value_col<0.8) & (value_col>0.65), value_col * 10)\n",
    "    .when((parameter_col == 'pH') & (value_col<80) & (value_col>65), value_col * 0.1)\n",
    "    .when((parameter_col == 'pH') & (value_col<800) & (value_col>650), value_col * 0.01)\n",
    "    .when((parameter_col == 'FiO2') & (value_col>1) & (value_col<=100), value_col * 0.1)\n",
    "    .when((parameter_col == 'FiO2') & (value_col<0.21), 0.21)\n",
    "    .when((parameter_col == 'Temp') & (value_col>1) & (value_col<10), value_col*9/5+32)\n",
    "    .when((parameter_col == 'Temp') & (value_col>95) & (value_col<113), (value_col-32)*5/9)\n",
    ")\n",
    "\n",
    "# use the features CSV file to remove outliers\n",
    "for var in features.index:\n",
    "    upper, lower = features.loc[var,['PlausibilityUpper','PlausibilityLower']]\n",
    "    if np.isnan(upper) & np.isnan(lower):\n",
    "        continue\n",
    "    if ~np.isnan(lower):\n",
    "        value = value.when((parameter_col == var) & (value_col < lower), lower)\n",
    "    if ~np.isnan(upper):\n",
    "        value = value.when((parameter_col == var) & (value_col > upper), upper)\n",
    "\n",
    "value = value.otherwise(value_col).alias(value_var)\n",
    "\n",
    "timeseries = (\n",
    "    timeseries\n",
    "    .select(\n",
    "        'RecordID',\n",
    "        'Dataset',\n",
    "        'Time',\n",
    "        'Parameter',\n",
    "        value\n",
    "    )\n",
    "    .filter(value_col.isNotNull())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the cleaned tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries.write.mode('overwrite').partitionBy('Dataset').parquet(str(TIMESERIES_FILE))\n",
    "static.write.mode('overwrite').parquet(str(STATIC_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform from tall to wide table and resample to the last value in each hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_cols = ['Dataset','RecordID','Bloc']\n",
    "for var in features.index:\n",
    "    wide_cols.append(F.when(parameter_col == var, value_col).otherwise(None).alias(var))\n",
    "\n",
    "wide = (\n",
    "    timeseries\n",
    "    .select(wide_cols)\n",
    "    .groupBy(['Dataset','RecordID','Time'])\n",
    "    .agg(*[F.last(F.col(var)).alias(var) for var in features.index])\n",
    "    .orderBy(['RecordID','Time'], ascending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to disk\n",
    "(\n",
    "    wide\n",
    "    .write\n",
    "    .mode('overwrite')\n",
    "    .partitionBy('Dataset')\n",
    "    .parquet(str(TIMESERIES_WIDE))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the wide table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = pd.read_parquet(TIMESERIES_WIDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>Bloc</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>...</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132539</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>set-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132539</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>set-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132539</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>set-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132539</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>set-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132539</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>set-a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID  Bloc  Albumin  ALP  ALT  AST  Bilirubin  BUN  Cholesterol  \\\n",
       "0    132539     1      NaN  NaN  NaN  NaN        NaN  NaN          NaN   \n",
       "1    132539     2      NaN  NaN  NaN  NaN        NaN  NaN          NaN   \n",
       "2    132539     3      NaN  NaN  NaN  NaN        NaN  NaN          NaN   \n",
       "3    132539     4      NaN  NaN  NaN  NaN        NaN  NaN          NaN   \n",
       "4    132539     5      NaN  NaN  NaN  NaN        NaN  NaN          NaN   \n",
       "\n",
       "   Creatinine  ...  RespRate  SaO2  SysABP  Temp  TroponinI  TroponinT  Urine  \\\n",
       "0         NaN  ...       NaN   NaN     NaN   NaN        NaN        NaN   60.0   \n",
       "1         NaN  ...       NaN   NaN     NaN   NaN        NaN        NaN   30.0   \n",
       "2         NaN  ...       NaN   NaN     NaN   NaN        NaN        NaN  170.0   \n",
       "3         NaN  ...       NaN   NaN     NaN   NaN        NaN        NaN   60.0   \n",
       "4         NaN  ...      20.0   NaN     NaN   NaN        NaN        NaN    NaN   \n",
       "\n",
       "   WBC  Weight  Dataset  \n",
       "0  NaN     NaN    set-a  \n",
       "1  NaN     NaN    set-a  \n",
       "2  NaN     NaN    set-a  \n",
       "3  NaN     NaN    set-a  \n",
       "4  NaN     NaN    set-a  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup: delete downloaded files and keep only the derived parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/set-b\n",
      "data/set-c\n",
      "data/set-a\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "def delete(file) -> None:\n",
    "    if os.path.isdir(file):\n",
    "        shutil.rmtree(file)\n",
    "    else:\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)\n",
    "            \n",
    "keep = [\n",
    "    TIMESERIES_FILE,\n",
    "    STATIC_FILE,\n",
    "    TIMESERIES_WIDE\n",
    "]\n",
    "for f in ROOT.glob(\"*\"):\n",
    "    if f not in keep:\n",
    "        print(f)\n",
    "        delete(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook physionet2012-prepare-data.ipynb to markdown\n",
      "[NbConvertApp] Writing 19549 bytes to physionet2012-prepare-data.md\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to markdown physionet2012-prepare-data.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
